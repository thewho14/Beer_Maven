{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I scrape data from the website beeradvocate.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import bs4\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#First go to the top 250 users webpage on beer advocate and parse it into a bs4 object\n",
    "res = requests.get('https://www.beeradvocate.com/members/?sort=beers')\n",
    "Soup = bs4.BeautifulSoup(res.text,'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get the url's for each individual user\n",
    "urls = [link.get('href') for link in Soup.find_all(class_='username')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/community/members/stonedtrippin.601042/',\n",
       " '/community/members/stonedtrippin.601042/',\n",
       " '/community/members/uclabrewn84.439438/',\n",
       " '/community/members/uclabrewn84.439438/',\n",
       " '/community/members/sammy.3853/',\n",
       " '/community/members/sammy.3853/',\n",
       " '/community/members/biboergosum.168458/',\n",
       " '/community/members/biboergosum.168458/',\n",
       " '/community/members/beerchitect.14442/',\n",
       " '/community/members/beerchitect.14442/']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get number of reviews for each user and remove extra junk\n",
    "numb = []\n",
    "for n in Soup.find_all(class_='username'):\n",
    "    numb.extend(n.find_next().find_next().contents)\n",
    "\n",
    "numb = [int(n.replace(',','')) for n in numb[:250]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remove duplicates and urls grab erroneously\n",
    "urls = [n for n in urls if n[0]=='/']\n",
    "urls = urls[::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stonedtrippin',\n",
       " 'uclabrewn84',\n",
       " 'sammy',\n",
       " 'biboergosum',\n",
       " 'beerchitect',\n",
       " 'metter98',\n",
       " 'brentk56',\n",
       " 'phyl21ca',\n",
       " 'superspak',\n",
       " 'nerofiddled']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract usernames from urls\n",
    "users = [r.replace('/community/members/','') for r in urls]\n",
    "users = [r.rsplit('.',1)[0] for r in users]\n",
    "users[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.beeradvocate.com/user/beers/?ba=stonedtrippin',\n",
       " 'https://www.beeradvocate.com/user/beers/?ba=uclabrewn84',\n",
       " 'https://www.beeradvocate.com/user/beers/?ba=sammy',\n",
       " 'https://www.beeradvocate.com/user/beers/?ba=biboergosum',\n",
       " 'https://www.beeradvocate.com/user/beers/?ba=beerchitect',\n",
       " 'https://www.beeradvocate.com/user/beers/?ba=metter98',\n",
       " 'https://www.beeradvocate.com/user/beers/?ba=brentk56',\n",
       " 'https://www.beeradvocate.com/user/beers/?ba=phyl21ca',\n",
       " 'https://www.beeradvocate.com/user/beers/?ba=superspak',\n",
       " 'https://www.beeradvocate.com/user/beers/?ba=nerofiddled']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create beer review url with username to find all beer rated by this user\n",
    "user_links = ['https://www.beeradvocate.com/user/beers/?ba='+ k for k in users]\n",
    "user_links[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add starting page number to access each page of reviews.  calculate that using total number of review/50 (50 per page)\n",
    "page_links = []\n",
    "for n in range(len(users)):\n",
    "    for k in range(0,numb[n],50):\n",
    "        page_links.append(user_links[n]+'&&start='+str(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.beeradvocate.com/user/beers/?ba=stonedtrippin&&start=0',\n",
       " 'https://www.beeradvocate.com/user/beers/?ba=stonedtrippin&&start=50',\n",
       " 'https://www.beeradvocate.com/user/beers/?ba=stonedtrippin&&start=100',\n",
       " 'https://www.beeradvocate.com/user/beers/?ba=stonedtrippin&&start=150',\n",
       " 'https://www.beeradvocate.com/user/beers/?ba=stonedtrippin&&start=200',\n",
       " 'https://www.beeradvocate.com/user/beers/?ba=stonedtrippin&&start=250',\n",
       " 'https://www.beeradvocate.com/user/beers/?ba=stonedtrippin&&start=300',\n",
       " 'https://www.beeradvocate.com/user/beers/?ba=stonedtrippin&&start=350',\n",
       " 'https://www.beeradvocate.com/user/beers/?ba=stonedtrippin&&start=400',\n",
       " 'https://www.beeradvocate.com/user/beers/?ba=stonedtrippin&&start=450']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#These are now working urls that take us to every rating the top 250 raters have made.\n",
    "page_links[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#initialize empty dataframe\n",
    "df = pd.DataFrame(columns = ['username','beer','rating','rDev'])\n",
    "ind = -1\n",
    "for link in range(len(page_links)):\n",
    "    #This part counts when page url's restart at 0 aka when we've moved on to the next user\n",
    "    if page_links[link][-2:] == '=0':\n",
    "        ind = ind + 1\n",
    "    try:\n",
    "        #Parse each webpage into bs4\n",
    "        rest = requests.get(page_links[link])\n",
    "        souper = bs4.BeautifulSoup(rest.text,'lxml')\n",
    "        \n",
    "        #Get rating and rDev and add in username\n",
    "        stuff = souper.find_all('b')[5:]\n",
    "        beer_names = np.array([k.contents[0] for k in stuff[:-1:2]])\n",
    "        ratings = np.array([p.contents[0] for p in stuff[1::2]])\n",
    "        rDev = np.array([r.find_next().text for r in stuff[1::2]])\n",
    "        col1 = np.repeat(users[ind],len(ratings))\n",
    "        #Get beer and brewery names\n",
    "        arc = souper.find_all('a')\n",
    "        duck = np.array([arc[n].contents for n in range(len(arc)) if str(arc[n].get('href'))[0:14]=='/beer/profile/'][1::2])\n",
    "        #Add to the empty dataframe\n",
    "        mat = pd.DataFrame(np.column_stack([col1,beer_names,duck,ratings,rDev]),columns = ['username','beer','brewery','rating','rDev'])\n",
    "        df = pd.concat([df,mat],ignore_index=True)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#basic data cleaning and saving to pkl file\n",
    "import sys\n",
    "sys.setrecursionlimit(10000)\n",
    "df.loc[:,'rating'] = pd.to_numeric(df.rating)\n",
    "#df.loc[:,'rDev'] = df.loc[:,'rDev'].str.replace('%','').str.replace('+','')\n",
    "df.loc[:,'rDev'] = pd.to_numeric(df.rDev)\n",
    "#df.drop(104081, inplace=True)\n",
    "#Assign each beer brewery combination a unique id number\n",
    "df = df.assign(beer_id=(df['brewery'] + '_' + df['beer']).astype('category').cat.codes)\n",
    "df = pickle.dump(df,open(\"Beer_Rating_Dataset.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(103930, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.sort_values('beer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(df.beer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[df.beer.str.contains('Corona')].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.groupby('username').mean().sort_values('rating',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.rating.hist()\n",
    "plt.xlabel('Ratings'); plt.ylabel('Number of Ratings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[['brewery','beer']].groupby('brewery').count().sort_values('beer',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['username','beer']].groupby('username').count().sort_values('beer',ascending=False).hist()\n",
    "plt.xlabel('Number of Beers Reviewed'); plt.ylabel('Number of People')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.assign(beer_id=(df['brewery'] + '_' + df['beer']).astype('category').cat.codes)\n",
    "#pickle.dump(df, open('Beer_User_df.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now its time to get the beer styles of each beer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Go to beer styles page\n",
    "res = requests.get('https://www.beeradvocate.com/beer/style/')\n",
    "Soup = bs4.BeautifulSoup(res.text,'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get urls\n",
    "urls = [link.get('href') for link in Soup.find_all('a')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#throw away bad urls\n",
    "good = [x for x in urls if type(x)==str]\n",
    "good[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#filter other bad urls\n",
    "better = [x for x in good if x[6:11]=='style']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#get ride of bad links at the start and end of list\n",
    "bet = better[2:-2]\n",
    "bet[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create actual urls\n",
    "bet = ['https://www.beeradvocate.com' + x + '?sort=revsD&start=0' for x in bet]\n",
    "bet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = requests.get(bet[0])\n",
    "ba = bs4.BeautifulSoup(res.text,'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#numb = ba.find_all('b')[4].contents[0].split('of ')[1].split(') -')[0]\n",
    "#int(numb)\n",
    "#first = [ba.find_all('a')[x].contents[0] for x in range(len(ba.find_all('a'))) if ba.find_all('a')[x].contents[0]>0]\n",
    "#second = [x.get('href') for x in first if x.get('href')[0:13]=='/beer/profile']\n",
    "dab = [ba.find_all('a')[x].contents for x in range(len(ba.find_all('a')))]\n",
    "#[dab[x+1] for x in range(len(dab)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grr = []\n",
    "for x in dab:\n",
    "    try:\n",
    "        if type(x[0]) == bs4.element.NavigableString:\n",
    "            grr.append(x[0])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ttt = grr[124:-13]\n",
    "ttt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get number of reviews.  The number is listed several ways and so the loop needs a way to catch all of them.\n",
    "numbs = []\n",
    "for r in range(len(bet)):\n",
    "    try:\n",
    "        res = requests.get(bet[r])\n",
    "        ba = bs4.BeautifulSoup(res.text,'lxml')\n",
    "        if ba.find_all('b')[3].contents[0][0:5]=='Style':\n",
    "            numb = ba.find_all('b')[3].contents[0].split('of ')[1].split(') -')[0]\n",
    "            numbs.append(int(numb))\n",
    "        else:\n",
    "            numb = ba.find_all('b')[2].contents[0].split('of ')[1].split(') -')[0]\n",
    "            numbs.append(int(numb))\n",
    "    except:\n",
    "        if ba.find_all('b')[4].contents[0][0:5]=='Style':\n",
    "                numb = ba.find_all('b')[4].contents[0].split('of ')[1].split(') -')[0]\n",
    "                numbs.append(int(numb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_links = []\n",
    "for n in range(len(bet)):\n",
    "    for k in range(0,numbs[n],50):\n",
    "        page_links.append(bet[n]+str(k))\n",
    "        \n",
    "page_links[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#get beer styles and names\n",
    "dg = pd.DataFrame(columns=['brewery','beer','type'])\n",
    "for link in range(len(page_links)):\n",
    "        try:\n",
    "            ttt = []\n",
    "            grr = []\n",
    "            print (float(link)/float(4000))*100\n",
    "            rest = requests.get(page_links[link])\n",
    "            souper = bs4.BeautifulSoup(rest.text,'lxml')\n",
    "            category = souper.find_all('h1')[0].contents[0]\n",
    "            beers = souper.find_all('b')[5:-1:3]\n",
    "            beers = [x.contents[0] for x in beers]\n",
    "            dab = [ba.find_all('a')[x].contents for x in range(len(ba.find_all('a')))]\n",
    "            for x in dab:\n",
    "                try:\n",
    "                    if type(x[0]) == bs4.element.NavigableString:\n",
    "                        grr.append(x[0])\n",
    "                        ttt = grr[124:-13]\n",
    "                except:\n",
    "                    pass\n",
    "            place = np.column_stack([ttt, beers])\n",
    "            dh = pd.DataFrame(place,columns = ['brewery', 'beer'])\n",
    "            dh.loc[:,'type'] = category\n",
    "            dg = pd.concat([dg,dh],ignore_index=True)\n",
    "        except:\n",
    "            print page_links[link]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(dg,open('beer_types_final.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dg.drop('brewery',axis=1, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beer Groups\n",
    "1. IPA/PA: American IPA, American Double/Imperial IPA, American Pale Ale (APA), Belgian IPA, Belgain Pale Ale, Belgian Strong Pale Ale, English India Pale Ale (IPA), \n",
    "2. Dark Ales (Amber/Red/Brown)\n",
    "3. Stouts/Porters\n",
    "4. Wheat Beer\n",
    "5. Dark Lager\n",
    "6. Light Lager\n",
    "7. Other(spiced,saisson)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
